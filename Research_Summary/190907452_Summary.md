## Summary: Blockchain Based Aggregator Free Federated Learning



## Abstract

- Kay aspect of FL -> requirement of a centralized aggregator to store and update the global model

- reduced computational cost on blockchain -> decomposing the global parameter space into distinct chunks

## Introduction

- **Centralized aggregator Jobs**
  - Resposible for delinearing the global computational pricess into distinct rounds
  - maintains a global estimate of the ML model to update
  - Selecting devices and sending a copy of the global model estimate to each
  - performing crtical step of updating the global model 
- **Problems of centralized aggregator design**
  - logistical challenges
  - trust in centralized aggregator's selection and update mechanism
    - if centralized aggregator is biased -> global model is biased
  - single point of failure, robustness concern
  - typically cloud based, small orgnization might not be able to implement this
    - result, high barrier of entry for small organizations
- **If using blockchain to decentralize the process, need to carefully consider the computational constraints**
  - data storage in blockchain -> significant cost
  - pushing an entire machine learning model to blockchain becomes computationally bulky -> heavy latency
  - transaction size limitation
- **BAFFLE** 
  - SC maintain global model copy and associated computational state of the user
  - Lower computational cost
  - selection of end users in baffle is based on the worth of their local updates
  - no cloud base, easier to use

## Smart FL Contract Design: Decentralizing Role of Aggregator

- **Chunking**
  - block size limit 24k from user's version
- **Scoring and bidding**
  - Each chunk is assigned a score by end user
- **Delineation of Rounds**
  - PL - Participation Level 
  - once start no new device area allowed to participate

## Computational Perspectives of BAFFLE

- User Level Actions:
  - Local Training
  - Model Aggregation and Update
    - A scalar score is assigned to each chunk based on the norm of the difference of the local weights with the global weights copy
  - <img src="/Users/danieltongawesome/Library/Application Support/typora-user-images/image-20200716153725775.png" alt="image-20200716153725775" style="zoom:40%;" />
- Global Perspective: The overall picture
  - ![image-20200716154216819](/Users/danieltongawesome/Library/Application Support/typora-user-images/image-20200716154216819.png)
  - A1, A2,  A3, A4, A5 Asset Devices
  - C1, C2, C3, C4, C5 Model Chuck

## Smart FL Contract Data Structure

- <img src="/Users/danieltongawesome/Library/Application Support/typora-user-images/image-20200719171421597.png" alt="image-20200719171421597" style="zoom:70%;" />
- 



## Some of My Thoughts

- Pros
  - Aggregator Free - Each local machine only in charges of updating one part of the model
- Cons
  - devices in this strucutres cannot go and join at anytime they want, this is more for research purposes I feel, under real industrial environment, a blockchain based system should let user to join and go at any time they want
  - Security - how about a node is malicious or been hacked or designed to destroy the trainning
  - No code provided, I really want to checkout their SC design and how to make the flow works
  - I did not get the point of use case study, to be honest, this example did not show the pain point of current Federate Learning, from my understanding:
    - 1. Sychronization - for model, how to use SC to sychronize everyone's work
      2. How to transfer model from one to another (under limited block size)
      3. Learning procedure 
  

